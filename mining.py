#!/bin/python3
import requests 
import urllib
import re
import random
import string
from bs4 import BeautifulSoup
#In this script, i took samples from https://www.unphp.net
default_url = "https://www.unphp.net"
digit = 5
#getting entire webpage provided by the url : https://www.unphp.net/recent/
html_page = requests.get("https://www.unphp.net/recent/")
soup = BeautifulSoup(html_page.content, 'html.parser')
Malware_links = []
count = 0	 #for malware files count 
for link in soup.findAll('a', attrs={'href': re.compile("\/decode\/")}):
    Malware_links.append(link.get('href')) 		#getting links of all recently decoded malwares with this site
for num in range(len(Malware_links)):
	default_url = default_url + Malware_links[num]
	malware_file_content = requests.get(default_url) 

	r1 = str(''.join(random.choices(string.ascii_uppercase + string.digits, k = digit)) )	 #default file names for reference
	path="/home/maryprincy/STASM/samples-from-script/" 		# path to save files
	default_url = "https://www.unphp.net"
	fullpath=path+r1
	fileextension=fullpath+".txt"      #file extension 
	count = count + 1
	with open(fileextension,'wb') as f:
		f.write(malware_file_content.content)
		
print(f"{count} Malware files are found. Files has been stored in Location : {path} ")


